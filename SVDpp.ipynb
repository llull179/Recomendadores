{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXhsb6rm1_y6"
      },
      "source": [
        "LightGCN para sistemas de recomendacion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zHkKWDBBZjck",
        "outputId": "628707d6-32a9-41ac-a92a-2aa2249eb218"
      },
      "outputs": [],
      "source": [
        "import surprise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "whMzg5Nl2kU6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.sparse import csr_matrix,lil_matrix\n",
        "\n",
        "RANDOM_STATE = 46\n",
        "train = pd.read_csv('./data/train.csv')\n",
        "test = pd.read_csv('./data/test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dCHMiJhq_Nq7",
        "outputId": "bca6ac3e-a286-4f00-a483-f4616b66363f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            "Training SVD++ model...\n",
            "Performing hyperparameter tuning...\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from surprise import Dataset, Reader, SVDpp\n",
        "from surprise.model_selection import train_test_split, cross_validate, GridSearchCV\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from surprise.accuracy import rmse\n",
        "\n",
        "# Step 1: Load and prepare the dataset\n",
        "# Assuming your data is in a CSV file with columns 'user', 'item', 'rating'\n",
        "def load_data(file_path):\n",
        "    # Load the data\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    # Define the format of the data\n",
        "    reader = Reader(rating_scale=(df['rating'].min(), df['rating'].max()))\n",
        "\n",
        "    # Load the data into the Surprise format\n",
        "    data = Dataset.load_from_df(df[['user', 'item', 'rating']], reader)\n",
        "\n",
        "    return data\n",
        "\n",
        "# Step 2: Train SVD++ model with hyperparameter tuning\n",
        "def train_svdpp_model(data):\n",
        "    # Split data into train and test sets\n",
        "    trainset, testset = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "    print(\"Performing hyperparameter tuning...\")\n",
        "    # Define parameter grid\n",
        "    param_grid = {\n",
        "        'n_factors': [20, 30, 40],\n",
        "        'n_epochs': [20],\n",
        "        'lr_all': [0.005, 0.01],\n",
        "        'reg_all': [0.02]\n",
        "    }\n",
        "\n",
        "    # Perform grid search\n",
        "    gs = GridSearchCV(SVDpp, param_grid, measures=['rmse', 'mae'], cv=3)\n",
        "    gs.fit(data)\n",
        "\n",
        "    # Get the best parameters\n",
        "    best_params = gs.best_params['rmse']\n",
        "    print(f\"Best parameters: {best_params}\")\n",
        "\n",
        "    # Train with best parameters\n",
        "    algo = SVDpp(\n",
        "        n_factors=best_params['n_factors'],\n",
        "        n_epochs=best_params['n_epochs'],\n",
        "        lr_all=best_params['lr_all'],\n",
        "        reg_all=best_params['reg_all'],\n",
        "        random_state=42,\n",
        "        verbose=True\n",
        "    )\n",
        "\n",
        "    # Train the model\n",
        "    algo.fit(trainset)\n",
        "\n",
        "    # Test the model\n",
        "    predictions = algo.test(testset)\n",
        "\n",
        "    # Calculate and print RMSE\n",
        "    test_rmse = rmse(predictions)\n",
        "    print(f\"Test RMSE: {test_rmse:.4f}\")\n",
        "\n",
        "    return algo, predictions\n",
        "\n",
        "# Step 3: Analyze the model's latent features\n",
        "def analyze_latent_features(algo, n_features=5):\n",
        "    # Get the user and item factors\n",
        "    user_factors = algo.pu\n",
        "    item_factors = algo.qi\n",
        "\n",
        "    # Print the shape of the matrices\n",
        "    print(f\"User factors shape: {user_factors.shape}\")\n",
        "    print(f\"Item factors shape: {item_factors.shape}\")\n",
        "\n",
        "    # Visualize feature distributions for first n features\n",
        "    plt.figure(figsize=(15, 10))\n",
        "\n",
        "    for i in range(min(n_features, user_factors.shape[1])):\n",
        "        plt.subplot(2, n_features, i+1)\n",
        "        plt.hist(user_factors[:, i], bins=50)\n",
        "        plt.title(f'User Feature {i+1}')\n",
        "\n",
        "        plt.subplot(2, n_features, i+1+n_features)\n",
        "        plt.hist(item_factors[:, i], bins=50)\n",
        "        plt.title(f'Item Feature {i+1}')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('latent_features.png')\n",
        "    plt.close()\n",
        "\n",
        "# Main function to run the whole process\n",
        "def main(file_path):\n",
        "    print(\"Loading data...\")\n",
        "    data = load_data(file_path)\n",
        "\n",
        "    print(\"Training SVD++ model...\")\n",
        "    algo, predictions = train_svdpp_model(data)\n",
        "\n",
        "    print(\"Analyzing latent features...\")\n",
        "    analyze_latent_features(algo)\n",
        "\n",
        "    return algo\n",
        "\n",
        "# Usage example\n",
        "\n",
        "# Replace with your actual file path\n",
        "file_path = \"./data/train.csv\"\n",
        "\n",
        "# Set to False if you want to skip hyperparameter tuning (faster)\n",
        "algo = main(file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>user</th>\n",
              "      <th>item</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>8117</td>\n",
              "      <td>268</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>10512</td>\n",
              "      <td>24393</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>534</td>\n",
              "      <td>1334</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>10984</td>\n",
              "      <td>6550</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>9093</td>\n",
              "      <td>22128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43315</th>\n",
              "      <td>43315</td>\n",
              "      <td>534</td>\n",
              "      <td>1751</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43316</th>\n",
              "      <td>43316</td>\n",
              "      <td>1150</td>\n",
              "      <td>5467</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43317</th>\n",
              "      <td>43317</td>\n",
              "      <td>10184</td>\n",
              "      <td>8805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43318</th>\n",
              "      <td>43318</td>\n",
              "      <td>7531</td>\n",
              "      <td>11566</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43319</th>\n",
              "      <td>43319</td>\n",
              "      <td>808</td>\n",
              "      <td>4571</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>43320 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          ID   user   item\n",
              "0          0   8117    268\n",
              "1          1  10512  24393\n",
              "2          2    534   1334\n",
              "3          3  10984   6550\n",
              "4          4   9093  22128\n",
              "...      ...    ...    ...\n",
              "43315  43315    534   1751\n",
              "43316  43316   1150   5467\n",
              "43317  43317  10184   8805\n",
              "43318  43318   7531  11566\n",
              "43319  43319    808   4571\n",
              "\n",
              "[43320 rows x 3 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Prediccion normal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictions = []\n",
        "    \n",
        "# Iterate through each row in the test data\n",
        "for _, row in test.iterrows():\n",
        "    user_id = row['user']\n",
        "    item_id = row['item']\n",
        "    id_value = row['ID']\n",
        "    \n",
        "    # Predict rating for this user-item pair\n",
        "    pred = algo.predict(uid=user_id, iid=item_id)\n",
        "    \n",
        "    # Store the prediction\n",
        "    predictions.append({\n",
        "        'ID': id_value,\n",
        "        'rating': pred.est\n",
        "    })\n",
        "\n",
        "# Create DataFrame from predictions\n",
        "result_df = pd.DataFrame(predictions)\n",
        "\n",
        "result_df.to_csv('./SVDpp.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Prediccion sustitucion media"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictions = []\n",
        "    \n",
        "# Iterate through each row in the test data\n",
        "\n",
        "user_train_set = set(train['user'].unique())\n",
        "item_train_set = set(train['item'].unique())\n",
        "\n",
        "for _, row in test.iterrows():\n",
        "\n",
        "    user_id = row['user']\n",
        "    item_id = row['item']\n",
        "    id_value = row['ID']\n",
        "\n",
        "    if user_id not in user_train_set and item_id not in item_train_set:\n",
        "        predicted_value = train['rating'].mean()\n",
        "    elif user_id not in user_train_set:\n",
        "        predicted_value = train[train['item'] == row['item']]['rating'].mean()\n",
        "    elif item_id not in item_train_set:\n",
        "        predicted_value = train[train['user'] == row['user']]['rating'].mean()\n",
        "    else:\n",
        "        predicted_value = algo.predict(uid=user_id, iid=item_id).est\n",
        "        \n",
        "    # Store the prediction\n",
        "    predictions.append({\n",
        "        'ID': id_value,\n",
        "        'rating': predicted_value\n",
        "    })\n",
        "\n",
        "# Create DataFrame from predictions\n",
        "result_df = pd.DataFrame(predictions)\n",
        "\n",
        "result_df.to_csv('./SVDpp_mean_unk.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Dado que las notas son valores enteros, probamos a redondear los valores para que sean enteros, ya que los valores finales son enteros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictions = []\n",
        "    \n",
        "# Iterate through each row in the test data\n",
        "\n",
        "user_train_set = set(train['user'].unique())\n",
        "item_train_set = set(train['item'].unique())\n",
        "\n",
        "for _, row in test.iterrows():\n",
        "\n",
        "    user_id = row['user']\n",
        "    item_id = row['item']\n",
        "    id_value = row['ID']\n",
        "\n",
        "    if user_id not in user_train_set and item_id not in item_train_set:\n",
        "        predicted_value = train['rating'].mean()\n",
        "    elif user_id not in user_train_set:\n",
        "        predicted_value = train[train['item'] == row['item']]['rating'].mean()\n",
        "    elif item_id not in item_train_set:\n",
        "        predicted_value = train[train['user'] == row['user']]['rating'].mean()\n",
        "    else:\n",
        "        predicted_value = algo.predict(uid=user_id, iid=item_id).est\n",
        "        \n",
        "    predicted_value = round(predicted_value)\n",
        "    # Store the prediction\n",
        "    predictions.append({\n",
        "        'ID': id_value,\n",
        "        'rating': predicted_value\n",
        "    })\n",
        "\n",
        "# Create DataFrame from predictions\n",
        "result_df = pd.DataFrame(predictions)\n",
        "\n",
        "result_df.to_csv('./SVDpp_round_mean_unk.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "main_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
